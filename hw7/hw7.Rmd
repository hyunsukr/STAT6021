---
title: "hw7"
author: "Hyun Suk (Max) Ryoo (hr2ee)"
date: "10/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set Up
```{r}
library(tidyverse)
library(datasets)
library(MASS)
data <- swiss
head(data)
```
## Question 1
1. For this first question, you will continue to use the dataset swiss which you also used in the last homework. Load the data. For more information about the data set, type ?swiss. The goal of the data set was to assess how fertility rates in the Swiss (French-speaking) provinces relate to a number of demographic variables.
    A) In the previous homework, you fit a model with the fertility measure as the response variable and used all the other variables as predictors. Now, consider a simpler model, using only the last three variables as predictors: Education, Catholic, and Infant.Mortality. Carry out an appropriate hypothesis test to assess which of these two models should be used. State the null and alternative hypotheses, find the relevant test statistic, p-value, and state a conclusion in context. (For practice, try to calculate the test statistic by hand.)

```{r}
full_model <- lm(Fertility~., data=data)
summary(full_model)
```


```{r}
simple_model <- lm(Fertility ~ Education + Catholic + Infant.Mortality, data=data)
summary(simple_model)
```

$H_0 : \beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 0$
$H_A : \text{not all} \beta_1, \beta_2, \beta_3, \beta_4, \beta_5 \text{are zero}$
The results of the partial F tests are shown below.
```{r}
anova(simple_model, full_model)
```
From the partial F test, we can observe a F-statistic of 3.0891 and a P-value of 0.05628. Since this p-value is above 0.05 we fail to reject the null hypothesis given our cut off value is 0.05. Therefore we should utilze the reduced model with only the three predictors. 

  B) For the model you decide to use from part 1a, assess if the regression assumptions are met.
```{r}
yhat = simple_model$fitted.values
res = simple_model$residuals
data %>%
  ggplot(aes(yhat, res)) + geom_point() + theme_bw() + geom_hline(yintercept=0, color="red")

```

From the above residual plot we can seee that the residuals are even scattered around 0, which is one asumption we need to check. 

```{r}
acf(simple_model$residuals, main="ACF Plot")
```

From the ACF plot we can observe the residual at lag one has some correlation, which may be a concern in some context. 

```{r}
{
qqnorm(simple_model$residuals)
qqline(simple_model$residuals, col="red")
}
```
The qqplot shows that the residuals fall close to the red line, which means that the normality assumption can be assumed. 

The final step is to check whether we need to transform the response variable. We can check this by observing if 1 falls between the boundaries of the boxcox plot, which by the figure below is true.
```{r}
boxcox(simple_model)
```

## Question 2  No R required (InfctRsk)
  2.A. Based on the t statistics, which predictors appear to be insignificant? 
From the table provided in the homework output, we can say that the Age, Cenus, and Beds variables appear to be insignificant

  2.B. Based on your answer in part 2a, carry out the appropriate hypothesis test to see if those predictors can be dropped from the multiple regression model. Show all steps, including your null and alternative hypotheses, the corresponding test statistic, p-value, critical value, and your conclusion in context.

$H_0 : \beta_3 = \beta_4 = \beta_5 = 0$
$H_A : \text{not all} \beta_3, \beta_4, \beta_5 \text{are zero}$

Since this question does not require R, we will find the F-Statisitic for the partial F test by hand.
$$
\begin{aligned}
F - Statistic &= \frac{\frac{0.136 + 5.101 + 0.028}{3}}{\frac{105.413}{107}} \\
F - Statistic &= \frac{1.755}{0.9851682}  \\
F - Statistic &= 1.781422
\end{aligned}
$$
The p - value can be found using a simple computation of $1 - pf(1.781422, 3, 107)$, which resulted in 0.1550925. 
```{r}
1 - pf(1.781422, 3, 107)
```

This p-value is greater than 0.05. We can also check by finding the cricial value, which can be computed using $qf(0.95,3,107)$, which is 2.68949.

```{r}
qf(0.95,3,107)
```
Since this value is greater than our f-statistic computed we fail to reject the null hytpohesis. Therefore, we can conclude that for the data provided we can utilize the simpler model. 

  2.C. Suppose we want to decide between two potential models:
  
  * Model 1: using x1, x2, x3, x4 as the predictors for InfctRsk
  * Model 2: using x1, x2 as the predictors for InfctRsk
  Carry out the appropriate hypothesis test to decide which of models 1 or 2 should be used. Be sure to show all steps in your hypothesis test.

$H_0 = \beta_3 = \beta_4 = 0$
$H_A = \text{at least one of the beta values is non zero}$

Since this question does not require R, we will find the F-Statisitic for the partial F test by hand.
$$
\begin{aligned}
F - Statistic &= \frac{\frac{0.136 + 5.101}{2}}{\frac{105.413 + 0.028}{113 -5}} \\
F - Statistic &= \frac{2.6185}{0.9763056}  \\
F - Statistic &= 2.68205
\end{aligned}
$$
The p - value can be found using a simple computation of $ 1 - pf(2.68205, 2, 108)$, which resulted in 0.07297992 
```{r}
1 - pf(2.68205, 2, 108)
```

This p-value is greater than 0.05. We can also check by finding the cricial value, which can be computed using $qf(0.95,3,107)$, which is 3.080387

```{r}
qf(0.95,2,108)
```

Since our f-statistic value is less than the critical value and the p-value is greater than 0.05 we fail to reject the null hypothesis. THerfore, we can utilize the simpler model (model 2). 

## Question 3  No R required (Left Arm, Left Foot, Rt Foot)
  3.A. Explain how this output indicates the presence of multicollinearity in this regression model.

The output indicates the presence of multicollinearity in this regression model because although the F test states our model is significant in predicting the response varible, none of the individual predictors are significant. Testing each variable one by one is needed and the possibility of multicolinearity needs to be considered. 



